// <auto-generated/>
#pragma warning disable CS0618
using Microsoft.Kiota.Abstractions.Extensions;
using Microsoft.Kiota.Abstractions.Serialization;
using System.Collections.Generic;
using System.IO;
using System;
namespace DoclingServe.Models
{
    [global::System.CodeDom.Compiler.GeneratedCode("Kiota", "1.0.0")]
    #pragma warning disable CS1591
    public partial class VlmModelApi : IAdditionalDataHolder, IParsable
    #pragma warning restore CS1591
    {
        /// <summary>Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.</summary>
        public IDictionary<string, object> AdditionalData { get; set; }
        /// <summary>Maximum number of concurrent requests to the API.</summary>
        public int? Concurrency { get; set; }
        /// <summary>Headers used for calling the API endpoint. For example, it could include authentication headers.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public global::DoclingServe.Models.VlmModelApi_headers? Headers { get; set; }
#nullable restore
#else
        public global::DoclingServe.Models.VlmModelApi_headers Headers { get; set; }
#endif
        /// <summary>Model parameters.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public global::DoclingServe.Models.VlmModelApi_params? Params { get; set; }
#nullable restore
#else
        public global::DoclingServe.Models.VlmModelApi_params Params { get; set; }
#endif
        /// <summary>Prompt used when calling the vision-language model.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public string? Prompt { get; set; }
#nullable restore
#else
        public string Prompt { get; set; }
#endif
        /// <summary>Type of response generated by the model.</summary>
        public global::DoclingServe.Models.ResponseFormat? ResponseFormat { get; set; }
        /// <summary>Scale factor of the images used.</summary>
        public double? Scale { get; set; }
        /// <summary>Temperature parameter controlling the reproducibility of the result.</summary>
        public double? Temperature { get; set; }
        /// <summary>Timeout for the API request.</summary>
        public double? Timeout { get; set; }
        /// <summary>Endpoint which accepts openai-api compatible requests.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public string? Url { get; set; }
#nullable restore
#else
        public string Url { get; set; }
#endif
        /// <summary>
        /// Instantiates a new <see cref="global::DoclingServe.Models.VlmModelApi"/> and sets the default values.
        /// </summary>
        public VlmModelApi()
        {
            AdditionalData = new Dictionary<string, object>();
            Prompt = "Convert this page to docling.";
        }
        /// <summary>
        /// Creates a new instance of the appropriate class based on discriminator value
        /// </summary>
        /// <returns>A <see cref="global::DoclingServe.Models.VlmModelApi"/></returns>
        /// <param name="parseNode">The parse node to use to read the discriminator value and create the object</param>
        public static global::DoclingServe.Models.VlmModelApi CreateFromDiscriminatorValue(IParseNode parseNode)
        {
            if(ReferenceEquals(parseNode, null)) throw new ArgumentNullException(nameof(parseNode));
            return new global::DoclingServe.Models.VlmModelApi();
        }
        /// <summary>
        /// The deserialization information for the current model
        /// </summary>
        /// <returns>A IDictionary&lt;string, Action&lt;IParseNode&gt;&gt;</returns>
        public virtual IDictionary<string, Action<IParseNode>> GetFieldDeserializers()
        {
            return new Dictionary<string, Action<IParseNode>>
            {
                { "concurrency", n => { Concurrency = n.GetIntValue(); } },
                { "headers", n => { Headers = n.GetObjectValue<global::DoclingServe.Models.VlmModelApi_headers>(global::DoclingServe.Models.VlmModelApi_headers.CreateFromDiscriminatorValue); } },
                { "params", n => { Params = n.GetObjectValue<global::DoclingServe.Models.VlmModelApi_params>(global::DoclingServe.Models.VlmModelApi_params.CreateFromDiscriminatorValue); } },
                { "prompt", n => { Prompt = n.GetStringValue(); } },
                { "response_format", n => { ResponseFormat = n.GetEnumValue<global::DoclingServe.Models.ResponseFormat>(); } },
                { "scale", n => { Scale = n.GetDoubleValue(); } },
                { "temperature", n => { Temperature = n.GetDoubleValue(); } },
                { "timeout", n => { Timeout = n.GetDoubleValue(); } },
                { "url", n => { Url = n.GetStringValue(); } },
            };
        }
        /// <summary>
        /// Serializes information the current object
        /// </summary>
        /// <param name="writer">Serialization writer to use to serialize this model</param>
        public virtual void Serialize(ISerializationWriter writer)
        {
            if(ReferenceEquals(writer, null)) throw new ArgumentNullException(nameof(writer));
            writer.WriteIntValue("concurrency", Concurrency);
            writer.WriteObjectValue<global::DoclingServe.Models.VlmModelApi_headers>("headers", Headers);
            writer.WriteObjectValue<global::DoclingServe.Models.VlmModelApi_params>("params", Params);
            writer.WriteStringValue("prompt", Prompt);
            writer.WriteEnumValue<global::DoclingServe.Models.ResponseFormat>("response_format", ResponseFormat);
            writer.WriteDoubleValue("scale", Scale);
            writer.WriteDoubleValue("temperature", Temperature);
            writer.WriteDoubleValue("timeout", Timeout);
            writer.WriteStringValue("url", Url);
            writer.WriteAdditionalData(AdditionalData);
        }
    }
}
#pragma warning restore CS0618
