// <auto-generated/>
#pragma warning disable CS0618
using Microsoft.Kiota.Abstractions.Extensions;
using Microsoft.Kiota.Abstractions.Serialization;
using System.Collections.Generic;
using System.IO;
using System;
namespace DoclingServe.Models
{
    [global::System.CodeDom.Compiler.GeneratedCode("Kiota", "1.0.0")]
    #pragma warning disable CS1591
    public partial class VlmModelLocal : IAdditionalDataHolder, IParsable
    #pragma warning restore CS1591
    {
        /// <summary>Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.</summary>
        public IDictionary<string, object> AdditionalData { get; set; }
        /// <summary>Config from https://huggingface.co/docs/transformers/en/main_classes/text_generation#transformers.GenerationConfig</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public global::DoclingServe.Models.VlmModelLocal_extra_generation_config? ExtraGenerationConfig { get; set; }
#nullable restore
#else
        public global::DoclingServe.Models.VlmModelLocal_extra_generation_config ExtraGenerationConfig { get; set; }
#endif
        /// <summary>Inference framework to use.</summary>
        public global::DoclingServe.Models.InferenceFramework? InferenceFramework { get; set; }
        /// <summary>Prompt used when calling the vision-language model.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public string? Prompt { get; set; }
#nullable restore
#else
        public string Prompt { get; set; }
#endif
        /// <summary>Repository id from the Hugging Face Hub.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public string? RepoId { get; set; }
#nullable restore
#else
        public string RepoId { get; set; }
#endif
        /// <summary>Type of response generated by the model.</summary>
        public global::DoclingServe.Models.ResponseFormat? ResponseFormat { get; set; }
        /// <summary>Scale factor of the images used.</summary>
        public double? Scale { get; set; }
        /// <summary>Temperature parameter controlling the reproducibility of the result.</summary>
        public double? Temperature { get; set; }
        /// <summary>Type of transformers auto-model to use.</summary>
        public global::DoclingServe.Models.TransformersModelType? TransformersModelType { get; set; }
        /// <summary>
        /// Instantiates a new <see cref="global::DoclingServe.Models.VlmModelLocal"/> and sets the default values.
        /// </summary>
        public VlmModelLocal()
        {
            AdditionalData = new Dictionary<string, object>();
            Prompt = "Convert this page to docling.";
            TransformersModelType = global::DoclingServe.Models.TransformersModelType.Automodel;
        }
        /// <summary>
        /// Creates a new instance of the appropriate class based on discriminator value
        /// </summary>
        /// <returns>A <see cref="global::DoclingServe.Models.VlmModelLocal"/></returns>
        /// <param name="parseNode">The parse node to use to read the discriminator value and create the object</param>
        public static global::DoclingServe.Models.VlmModelLocal CreateFromDiscriminatorValue(IParseNode parseNode)
        {
            if(ReferenceEquals(parseNode, null)) throw new ArgumentNullException(nameof(parseNode));
            return new global::DoclingServe.Models.VlmModelLocal();
        }
        /// <summary>
        /// The deserialization information for the current model
        /// </summary>
        /// <returns>A IDictionary&lt;string, Action&lt;IParseNode&gt;&gt;</returns>
        public virtual IDictionary<string, Action<IParseNode>> GetFieldDeserializers()
        {
            return new Dictionary<string, Action<IParseNode>>
            {
                { "extra_generation_config", n => { ExtraGenerationConfig = n.GetObjectValue<global::DoclingServe.Models.VlmModelLocal_extra_generation_config>(global::DoclingServe.Models.VlmModelLocal_extra_generation_config.CreateFromDiscriminatorValue); } },
                { "inference_framework", n => { InferenceFramework = n.GetEnumValue<global::DoclingServe.Models.InferenceFramework>(); } },
                { "prompt", n => { Prompt = n.GetStringValue(); } },
                { "repo_id", n => { RepoId = n.GetStringValue(); } },
                { "response_format", n => { ResponseFormat = n.GetEnumValue<global::DoclingServe.Models.ResponseFormat>(); } },
                { "scale", n => { Scale = n.GetDoubleValue(); } },
                { "temperature", n => { Temperature = n.GetDoubleValue(); } },
                { "transformers_model_type", n => { TransformersModelType = n.GetEnumValue<global::DoclingServe.Models.TransformersModelType>(); } },
            };
        }
        /// <summary>
        /// Serializes information the current object
        /// </summary>
        /// <param name="writer">Serialization writer to use to serialize this model</param>
        public virtual void Serialize(ISerializationWriter writer)
        {
            if(ReferenceEquals(writer, null)) throw new ArgumentNullException(nameof(writer));
            writer.WriteObjectValue<global::DoclingServe.Models.VlmModelLocal_extra_generation_config>("extra_generation_config", ExtraGenerationConfig);
            writer.WriteEnumValue<global::DoclingServe.Models.InferenceFramework>("inference_framework", InferenceFramework);
            writer.WriteStringValue("prompt", Prompt);
            writer.WriteStringValue("repo_id", RepoId);
            writer.WriteEnumValue<global::DoclingServe.Models.ResponseFormat>("response_format", ResponseFormat);
            writer.WriteDoubleValue("scale", Scale);
            writer.WriteDoubleValue("temperature", Temperature);
            writer.WriteEnumValue<global::DoclingServe.Models.TransformersModelType>("transformers_model_type", TransformersModelType);
            writer.WriteAdditionalData(AdditionalData);
        }
    }
}
#pragma warning restore CS0618
